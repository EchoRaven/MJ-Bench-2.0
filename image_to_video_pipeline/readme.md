### 批量视频生成文档

#### 概述
本文档描述了如何使用Stable Diffusion技术将一系列图片批量转换成视频文件。该过程通过Python脚本 `generate.py` 和相应的 Bash 脚本进行操作控制。

#### 文件说明
- **generate.py**: Python 脚本，负责从输入的JSON文件中读取图片路径和相关数据，利用 Stable Diffusion 模型生成视频，并保存输出结果到指定的JSON文件和目录。
- **bash脚本**: 设置脚本参数，调用 `generate.py` 执行视频生成任务。

#### 参数设置
- `INPUT_JSON`: 指向包含图片信息的输入 JSON 文件的路径。
- `OUTPUT_JSON`: 输出 JSON 文件的存储路径，用于记录视频生成结果。
- `VIDEO_OUTPUT_DIR`: 生成的视频文件存储的目录。
- `CACHE_DIR`: 模型缓存目录，用于存储下载的或预先加载的模型数据。
- `FRAME_COUNT`: 每个视频生成的帧数。
- `FRAME_DURATION`: 每帧的持续时间（毫秒）。

#### 使用说明
1. **环境配置**：确保Python环境已安装 `diffusers`、`PIL`、`torch`、`tqdm` 和 `cv2` 等库。
2. **运行Bash脚本**：
   - 打开终端。
   - 使用 `cd` 命令切换到脚本所在的目录。
   - 运行脚本：输入 `bash run_script.sh`，按Enter执行，或者chmod给权限后./执行。
   - 脚本将自动设置所需的环境变量，调用 `generate.py` 进行视频生成。
   - 可通过 `--debug` 参数运行测试模式，此模式只处理少量数据以验证脚本功能。

#### 功能描述
- **视频生成**：根据指定的图片和帧数，通过 Stable Diffusion 生成连续的视频帧。
- **格式支持**：支持输出 GIF 或 MP4 格式的视频文件。
- **多GPU支持**：脚本支持多GPU并行处理，加速视频生成过程。pipeline会自动在visible的GPU中选用显存空余最多的GPU建立进程。

#### 注意事项
- 确保所有指定的路径都是有效的且具有足够的读写权限。
- 检查 GPU 可用性和配置，确保脚本能正确执行。
- 脚本中的错误处理逻辑帮助识别和解决在视频生成过程中可能遇到的问题。

此文档旨在帮助用户理解和使用视频生成脚本，通过Stable Diffusion技术快速从图片生成视频内容。